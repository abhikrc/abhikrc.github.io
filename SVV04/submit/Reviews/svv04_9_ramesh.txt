
Paper # ?

Title: A Technique for Verification of Race Conditions in Real-time Systems

Authors: Telkar, Chata, Lee, Gannod and Wong.


1 - How do you classify this paper?

   3: Strong Accept

   2: Weak Accept   <--

   1: Weak Reject

   0: Strong Reject



 
 2 - What is your overall expertise concerning the subject areas of this
paper?

   X: I am an expert.   <--
   Y: I am knowledgeable in the area, though not an expert  
   Z: I am not an expert. My evaluation is that of an informed outsider.



 3 - Main Contributions of the paper

The authors model several synchronization mechanisms of VxWorks and
verify, using the model checking tool UPPAAL, that they satisfy
several safety and liveness properties.  Also, they present UPPAAL
models (they do not say how or where they got them from) that violate
the safety property which they characterize as a data race.


 4 - Points in favour or against the paper

The paper is very well written and presents several examples that
would be of use to a novice modeller/user of UPPAAL.  It is a
tutorial-style introduction to the tool, the modelling language
and the property specification language, illustrated by several
examples.  However, the models they present may be equally well
be verified using a finite-state model checker such as spin, i.e.,
although they say in the introduction that they are timed-automata
models, they do not really exercise the "timed" extensions in the
tool.  Also, the paper is weak in presenting related work and the
(ir-)relevance of model checking in finding bugs in real systems.
Finally, the examples for which they detect race conditions are
"cooked" in the sense that the authors never make their case for
model checking by stating whether these races were detected by
model checking (I strongly suspect this was not the case), and if so,
the specific property violation that led to their discovery.

The authors also do not address the limitations of ad-hoc model construction
and property verification.  As with other manual model checking
exercises, we are unsure whether (a) the models are true abstractions
of the code (b) whether the counterexamples generated by the model
checker are true property violations in the code and (c) whether the
properties being verified collectively imply the requirements of the
synchronization mechanisms being modelled.  In other words, the models
may be unsound and/or incomplete abstractions of the code, thereby making
the whole exercise a guessing game where one is unsure whether an error
detected by the model checker is truly an error, and precisely what
conclusions are entailed by a successful run of the model checker.

 5- Specific Comments for improving the paper

The authors should realize that exercises in model checking are no
longer a novelty.  In essence, the larger questions (that I raise
above) about the utility of this approach, and compelling arguments
about the use of the technique in preference to, for example,
testing, are the unanswered questions in this field.  Also, it is
not clear whether a business case can be made for model checking
exercises such as the one presented in this paper as a true alternative
to current engineering methods such as testing and code inspection.

-------------------------


